{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 06: Spark and Least Squares Linear Regression\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this assignment, you will implement distributed least squares linear regression using Apache Spark. As with Lab09 we will be using a service called Databricks to develop and run code. Databricks simplifies the setup of Apache Spark and the cloud, and it provides limited free cloud computing. Outside the context of this assignment, you can always run Apache Spark code on your own computer or in the cloud without Databricks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw6.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(16)\n",
    "\n",
    "# For instructor use only. Call this function to force refresh okpy tests\n",
    "def refresh():\n",
    "    import sys\n",
    "    keys = [k for k in sys.modules.keys() if 'ok_tests' in k]\n",
    "    for k in keys:\n",
    "        del sys.modules[k]\n",
    "    global ok\n",
    "    ok = Notebook('hw6.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ok.auth(force=False) # Change False to True if you are getting errors authenticating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Understanding Least Squares Regression\n",
    "\n",
    "\n",
    "In the first part of this homework, we explore some properties of multiple regression.  In particular, the goals are to\n",
    "\n",
    "* Interpret of parameters in simple and multiple linear regression\n",
    "* Understand how the correlation of the explanatory variables can impact the coefficients\n",
    "* Observe how te correlation between explanatry variables can impact the standard error of the coefficients.\n",
    "\n",
    "\n",
    "We will also introduce the tools in scikit learn for fitting linear models. Note that these tools are not used in the second part of this assignment where you implement linear least squares using Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from IPython.display import display, Latex, Markdown\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Data\n",
    "\n",
    "We generate two sets of data, a response vector `Y` and a two-column design matrix `X`. \n",
    "\n",
    "* In the first data set, the columns of `X` are correlated with each other as well as being correlated with `Y`.  \n",
    "* In the second data set, the columns of `X` are uncorrelated with each other and both columns are correlated with `Y`.   \n",
    "\n",
    "The following code creates the first data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 2\n",
    "\n",
    "mean = [0, 0, 0]\n",
    "cov = [[1, 0.7, 0.7], [0.7, 1, 0.9], [0.7, 0.9, 1]]\n",
    "\n",
    "np.random.seed(1141)\n",
    "v, u, Y = np.random.multivariate_normal(mean, cov, n).T\n",
    "X = np.array([u, v]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1a \n",
    "Find the mean and standard deviation of `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "mean_Y = np.mean(Y)\n",
    "sd_Y = np.std(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q01a"
    ]
   },
   "outputs": [],
   "source": [
    "assert np.isclose(mean_Y, -0.0278106)\n",
    "assert np.isclose(sd_Y, 1.0052497653)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three-dimensional plot\n",
    "\n",
    "Create a 3D plot of `Y` and `X`. \n",
    "Take the following plot for a spin (literally).  Drag across the plot to spin it. Notice that we added the origin in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X[:,0], X[:,1], Y)\n",
    "# Added the origin \n",
    "ax.scatter([0],[0],[0], \"o\", color='red')\n",
    "ax.set_xlabel(r\"$X_0$ axis\")\n",
    "ax.set_ylabel(r'$X_1$ axis')\n",
    "ax.set_zlabel('Y axis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1b\n",
    "Spin the plot to examine the range of $X_0$, $X_1$ and $Y$. State whether each statement is true or false.\n",
    "\n",
    "1. The range of $X_0$ and $X_1$ are both from about -2 to 2\n",
    "1. Together $X_0$ and $X_1$ nearly fill their respective plane.\n",
    "1. The response $Y$ appears correlated with both $X_0$ and $X_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "written",
     "q01b"
    ]
   },
   "outputs": [],
   "source": [
    "Q1b_answer = '''\n",
    "\n",
    "1. True. \n",
    "1. False. \n",
    "1. True.\n",
    "\n",
    "'''\n",
    "\n",
    "display(Markdown(Q1b_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1c \n",
    "In addition to the 3D plot, examine the three pairwise scatter plots:\n",
    "\n",
    "* `Y` and the first column of `X`\n",
    "* `Y` and the second column of `X`\n",
    "*  the two columns of `X`\n",
    "\n",
    "Arrange your 3 plots in a 2 by 2 grid (with one empty facet).\n",
    "\n",
    "Label your axes so that you can tell which plot is which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,9))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(X[:,0], Y, 'o')\n",
    "plt.ylabel(\"Y\")\n",
    "plt.xlabel(r\"$X_0$\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(X[:,1], Y, 'o')\n",
    "plt.xlabel(r\"$X_1$\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(X[:,0], X[:,1], 'o')\n",
    "plt.ylabel(r\"$X_1$\")\n",
    "plt.xlabel(r\"$X_0$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is difficult to see how $Y$ depends on both $X_0$ and $X_1$ together in the pairwise plots.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1d \n",
    "Use 'corrcoef' to find the correlation matrix of all pairwise correlation \n",
    "coefficients between $Y$, $X_0$ and $X_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "corr = np.corrcoef([X[:,0], X[:,1], Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q01d"
    ]
   },
   "outputs": [],
   "source": [
    "assert np.isclose(corr[0,2] , 0.91453913)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a least squares linear model \n",
    "\n",
    "Let's compare the coefficients of the least squares fit for the following models\n",
    "\n",
    "* $Y$ as a linear function of $X_0$\n",
    "* $Y$ as a linear function of $X_1$\n",
    "* $Y$ as a linear function of $X_0$ and $X_0$\n",
    "\n",
    "\n",
    "#### Question1e\n",
    "Use 'linear_model' in scikit learn to fit the models and examine the coefficients.\n",
    "Do not fit an intercept term in any of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Fit Y to the first column of X\n",
    "model_1 = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_1.fit(X[:,[0]],Y)\n",
    "print(\"Y ~ X_0 coefficient:\", model_1.coef_)\n",
    "\n",
    "# Fit Y to the second column of X\n",
    "model_2 = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_2.fit(X[:,[1]],Y)\n",
    "print(\"Y ~ X_1 coefficient:\", model_2.coef_)\n",
    "\n",
    "# Fit Y to X\n",
    "model_3 = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_3.fit(X[:,[0,1]], Y)\n",
    "print(\"Y ~ (X_0, X_1) coefficients:\", model_3.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q01e"
    ]
   },
   "outputs": [],
   "source": [
    "assert np.allclose(model_2.coef_ , 0.70705475)\n",
    "assert np.allclose(model_3.coef_[1] , 0.21381339)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-plots\n",
    "\n",
    "Compare the coefficients from the simple linear fit to the coefficients in the two-variable fit. Notice that the coefficient for $X_1$ has changed quite a bit. It is $0.71$ in the single variable model and only $0.21$ in the two-variable model.\n",
    "\n",
    "The coefficients in the two-variable model depend on the presence of the other explanatory variables in the model. \n",
    "\n",
    "In this case since $X_0$ is in the model and it is very highly correlated with $Y$, then $X_1$ does not explain much additional variation in $Y$. That is, given $X_0$, the relationship between $Y$ and $X_1$ is not as strong as the relationship between $Y$ and $X_1$ without knowledge of $X_0$.\n",
    "\n",
    "We can see this when we plot $Y$ on $X_1$ for subgroups of the data where $X_0$ is roughly constant. \n",
    "\n",
    "#### Question1f\n",
    "\n",
    "Create four scatter plots of the relationship between $Y$ and $X_1$, conditioned on $X_0$. \n",
    "To do this, bin $X_0$ into the following categories: -4 to -1, -1 to 0, 0 to 1, and 1 to 4.\n",
    "For each subset of records, make a scatter plot $Y$ and $X_1$. In your plot be sure to\n",
    "\n",
    "* Keep the $Y$ limits the same on all 4 plots\n",
    "* Keep the $X_1$ limits the same on all 4 plots\n",
    "* Provide a title that indicates which subgroup of records is being plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,9))\n",
    "bins = [-4, -1, 0, 1, 4]\n",
    "\n",
    "for i in range(1, len(bins)):\n",
    "    ind = (X[:,0] > bins[i-1]) & (X[:,0] < bins[i])\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.plot(X[ind,1], Y[ind], 'o')\n",
    "    plt.xlim([-3,3])\n",
    "    plt.ylim([-3,3])\n",
    "    plt.ylabel(r\"Y\")\n",
    "    plt.title(str(bins[i-1])+ r\"$< X_0 <$\" + str(bins[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1g\n",
    "How does the relationship between $Y$ and $X_1$ change from the plot made in Q1d to these plots? State whether each statement is true or false.\n",
    "\n",
    "1. There is a stronger linear relationship between $Y$ and $X_1$ in the plot in Q1d than in the group of 4 plots\n",
    "1. Each of the above 4 plots shows a similar strength of relationship between $Y$ and $X_1$\n",
    "1. The average levels of $Y$ in the 4 plots are about the same in all 4 plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "Q1g_answer = '''\n",
    "\n",
    "1. True. \n",
    "1. True. \n",
    "1. False.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "display(Markdown(Q1g_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1h\n",
    "\n",
    "Lastly, we examine the multiple correlation coefficient from the regression.\n",
    "\n",
    "The multiple correlation coefficient is the ratio of the explained variation in $Y$ (i.e., the variation in $Y$ that has been explained by the linear fit, or the variation in $\\hat{Y}$) to the total variation in $Y$. It is similar in spirit to the correlation coefficient from lab, but is useful for the multiple regression case. \n",
    "\n",
    "Compute the multiple $R^2$ for the 2-variable regression. To do this, \n",
    "\n",
    "* Compute the predicted values, $\\hat{Y}$\n",
    "* Compute the ratio of the explained variation $||\\hat{Y} - \\bar{Y}||^2$ to the total variation $||Y - \\bar{Y}||^2$ using `r2_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "Y_hat = model_3.predict(X)\n",
    "multiple_R2 = r2_score(Y, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q01h"
    ]
   },
   "outputs": [],
   "source": [
    "assert np.isclose(multiple_R2, 0.86225295102790045)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncorrelated explanatory variables\n",
    "\n",
    "Now repeat the investigation that you have done above with a different data set. Compare the plots for these data to the plots that you made with the first set of data.\n",
    "\n",
    "First, run the following code chunk to create the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21141)\n",
    "mean = [0, 0, 0]\n",
    "cov = [[1, 0.7, 0.7], [0.7, 1, 0.], [0.7, 0., 1]]\n",
    "\n",
    "Y, u, v = np.random.multivariate_normal(mean, cov, n).T\n",
    "X = np.array([u, v]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the 3D plot of $Y$ and $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X[:,0], X[:,1], Y)\n",
    "# Added the origin \n",
    "ax.scatter([0],[0],[0], \"o\", color='red')\n",
    "ax.set_xlabel(r\"$X_0$ axis\")\n",
    "ax.set_ylabel(r'$X_1$ axis')\n",
    "ax.set_zlabel('Y axis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Make three pairwise plots\n",
    "\n",
    "* `Y` and the first column of `X`\n",
    "* `Y` and the second column of `X`\n",
    "*  the two columns of `X`\n",
    "\n",
    "Arrange your 3 plots in a 2 by 2 grid (with one empty facet).\n",
    "\n",
    "Label your axes so that you can tell which plot is which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,9))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(X[:,0], Y, 'o')\n",
    "plt.ylabel(\"Y\")\n",
    "plt.xlabel(r\"$X_0$\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(X[:,1], Y, 'o')\n",
    "plt.xlabel(r\"$X_1$\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(X[:,0], X[:,1], 'o')\n",
    "plt.ylabel(r\"$X_1$\")\n",
    "plt.xlabel(r\"$X_0$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the pairwise correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "np.corrcoef([X[:,0], X[:,1], Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-plots\n",
    "\n",
    "Create scatter plots of the relationship between $Y$ and $X_1$, conditioned on $X_0$. Bin $X_0$ into the following categories: -4 to -1, -1 to 0, 0 to 1, and 1 to 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,9))\n",
    "bins = [-4, -1, 0, 1, 4]\n",
    "\n",
    "for i in range(1, len(bins)):\n",
    "    ind = (X[:,0] > bins[i-1]) & (X[:,0] < bins[i])\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.plot(X[ind,1], Y[ind], 'o')\n",
    "    plt.xlim([-3,3])\n",
    "    plt.ylim([-3,3])\n",
    "    plt.ylabel(r\"Y\")\n",
    "    plt.title(str(bins[i-1])+ r\"$< X_0 <$\" + str(bins[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the least squares linear models \n",
    "\n",
    "As before fit the following models and compare the coefficients\n",
    "\n",
    "* $Y$ as a linear function of $X_0$\n",
    "* $Y$ as a linear function of $X_1$\n",
    "* $Y$ as a linear function of $X_0$ and $X_0$\n",
    "\n",
    "Do not fit an intercept term in any of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Fit Y to the first column of X\n",
    "model_1_second = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_1_second.fit(X[:,[0]],Y)\n",
    "print(\"Y ~ X_0 coefficient:\", model_1.coef_)\n",
    "\n",
    "# Fit Y to the second column of X\n",
    "model_2_second = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_2_second.fit(X[:,[1]],Y)\n",
    "print(\"Y ~ X_1 coefficient:\", model_2.coef_)\n",
    "\n",
    "# Fit Y to X\n",
    "model_3_second = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_3_second.fit(X[:,[0,1]], Y)\n",
    "print(\"Y ~ (X_0, X_1) coefficients:\", model_3.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the multiple correlation coefficient for the 2-variable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "Y_hat_second = model_3.predict(X)\n",
    "multiple_R2_second = r2_score(Y, Y_hat_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1i\n",
    "Now it's time to compare your findings of the two data sets.\n",
    "\n",
    "Answer the following questions.\n",
    "\n",
    "1. In the 3D plot, consider the spread of points in the $X_0$, $X_1$ plane. Do the two sets of data fill this plane similarly?\n",
    "1. Compare the pairwise scatter plots of ($X_0$, $Y$) and ($X_1$, $Y$), and ($X_0$, $X_1$). Two of the pairs should look roughly the same for the different data sets and one should look different. Which one is different across the two data sets? How is it different? \n",
    "1. Examine the 4 co-plots for the second set of data. Is the slope of the linear relationship for these plots roughly the same? Is the strength of the relationship roughly the same? How does the linear relationship in these 4 plots compare to the relationship observed between $X_1$ and $Y$ without conditioning on $X_0$?\n",
    "1. Compare the 4 co-plots for the two sets of data. the How are they different? How are they the same?\n",
    "1. Consider how the single variable and two-variable coefficients change in the regressions for the second data set. How is this change different than the change observed for the first data set?\n",
    "1. Compare the multiple $R^2$ of the two-variable regression for the two data sets. Do you think this $R^2$ gives any indication of whether the two variable regression would have different coefficients for the explanatory variables than the one variable regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "written",
     "q01i"
    ]
   },
   "outputs": [],
   "source": [
    "Q1i_answer = '''\n",
    "\n",
    "1. The second data set fills the $X_0$, $X_1$ plane more than the first data set. \n",
    "This is because $X_0$ and $X_1$ are nearly uncorrelated.\n",
    "1. The pairwise scatter plots of ($X_0$, $Y$) and ($X_1$, $Y$) look roughly the same for the \n",
    "two sets of data. The scatter plot of the two explanatory variables ($X_0$, $X_1$) look quite different.\n",
    "We see that ($X_0$, $X_1$) do not appear very correlated.  \n",
    "1. The 4 co-plots for the second set of data each show a strong linear association. \n",
    "The slope of the linear relationship for these plots remains roughly the same.\n",
    "And, the linear relationship in these 4 plots is similar in strength to the relationship\n",
    "between $X_1$ and $Y$ without conditioning on $X_0$. This is because $X_0$ and $X_1$ have a weak correlation\n",
    "so information about $X_0$ does not impact the relationship between $X_1$ and $Y$.\n",
    "1. The 4 co-plots for the first set of data are quite differnt than those of the second set. \n",
    "The first set show a weak correlation between $X_1$ and $Y$.\n",
    "1. The coefficient for $X_1$ in the single variable regression is similar to its coefficient\n",
    "in the two-variable regression.  It changes somewhat, but not anywhere near as much as for\n",
    "the first set of data.  The same is true for the coefficient for $X_0$.  This is because \n",
    "$X_0$ and $X_1$ are nearly uncorrelated so they do not explain the same variablitliy in $Y$.\n",
    "1. The multiple $R^2$ of the two-variable regression for the two data sets are both quite high.\n",
    "They do not provide any information about the collinearity in the design. \n",
    "\n",
    "'''\n",
    "\n",
    "display(Markdown(Q1i_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "In this question we will use Apache Spark to compute the statistics needed to solve the ordinary least squared linear regression problem.\n",
    "\n",
    "**Note: Apache Spark already has estimate a wide range of models including linear regression.  However we will be doing this by hand (for practice).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Setup\n",
    "\n",
    "Step 1 is to create a Databricks account.  Go [here](https://accounts.cloud.databricks.com/registration.html#signup/community) to sign up.  Use your @berkeley email address. If you have already signed up before (in lab), go to [this](https://community.cloud.databricks.com/) page to login directly.\n",
    "\n",
    "After you sign up, sign in to your Databricks account, then click Workspace -> Users -> `<your-username>@berkeley.edu`.    Click on the arrow pointing down beside your email address and select **`Import`**.  Import the `hw06.dbc` file in this folder containing this notebook.\n",
    "\n",
    "![Importing](https://github.com/DS-100/sp17-materials/blob/master/sp17/hw/hw7/importing_notebooks.png?raw=true)\n",
    "\n",
    "This will create a Databricks notebook file.  Open it.\n",
    "\n",
    "The rest of this assignment is primarily conducted in the Databricks notebook.  However, this notebook contains the OK tests you can use to check your work, and it contains the invocations to submit your assignment when you're done.  Follow the instructions in the Databricks notebook to download your results in a form that the tests here will understand.\n",
    "\n",
    "** Issue: **\n",
    "1. Databricks Cloud runs Python 2.7 so you won't be able to use `X.T @ Y` operator.  Instead you can use `X.T.dot(Y)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2a\n",
    "\n",
    "Complete question 2a and paste answer below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "size_of_diamonds = 3192560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02a"
    ]
   },
   "outputs": [],
   "source": [
    "assert size_of_diamonds > 3100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2b\n",
    "Complete question 2b and paste your answer below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "number_of_rows = 53940"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02b"
    ]
   },
   "outputs": [],
   "source": [
    "assert number_of_rows > 53900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2c\n",
    "\n",
    "The size of the training data after constructing a 90/10 train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "number_of_rows_in_training = 48646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02c"
    ]
   },
   "outputs": [],
   "source": [
    "assert number_of_rows_in_training > 48000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2d\n",
    "\n",
    "The average price of diamonds in the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "avg_price_of_diamonds_in_training = 3921.282674834481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02d"
    ]
   },
   "outputs": [],
   "source": [
    "assert avg_price_of_diamonds_in_training > 3920\n",
    "assert avg_price_of_diamonds_in_training < 3922"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3a\n",
    "The value of $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "theta = [  7865.41870378,   -147.65515738,   -101.57023038,  12608.52774277]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q03a"
    ]
   },
   "outputs": [],
   "source": [
    "assert len(theta) == 4\n",
    "assert (theta[0] > 7864) and (theta[0] < 7866)\n",
    "assert (theta[1] > -148) and (theta[1] < -146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3b\n",
    "It seems like the weight of `carat` is way bigger than the other two, could we say it is the dominating feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "q03b"
    ]
   },
   "outputs": [],
   "source": [
    "#solution:\n",
    "#No, since the usual value of feature `carat` is small than 1, while the other two are around 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3c\n",
    "Compute the RMSE for $\\theta$ estimated using carat, depth, table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "#solution\n",
    "rmse = 1522.3582303379176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q03c"
    ]
   },
   "outputs": [],
   "source": [
    "assert rmse >1522\n",
    "assert rmse <1523\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3d\n",
    "Compute the improved RMSE using more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_improved = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "#solution\n",
    "rmse_improved = 1490.4978047105708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q03d"
    ]
   },
   "outputs": [],
   "source": [
    "assert rmse_improved < 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3e\n",
    "Compute the improved test RMSE using additional one-hot features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rmse = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "#solution\n",
    "test_rmse = 1391.14006912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q03e"
    ]
   },
   "outputs": [],
   "source": [
    "assert test_rmse < 1400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting your assignment\n",
    "Congratulations, you're done with this homework!\n",
    "\n",
    "Run the next cell to run all the tests at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to submit your assignment to OkPy. The autograder should email you shortly with your autograded score. The autograder will only run once every 30 minutes.\n",
    "\n",
    "**If you're failing tests on the autograder but pass them locally**, you should simulate the autograder by doing the following:\n",
    "\n",
    "1. In the top menu, click Kernel -> Restart and Run all.\n",
    "2. Run the cell above to run each OkPy test.\n",
    "\n",
    "**You must make sure that you pass all the tests when running steps 1 and 2 in order.** If you are still failing autograder tests, you should double check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}