{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: SQL, FEC Data, and Small Donors\n",
    "\n",
    "## Due: 11:59pm Tuesday, November 7\n",
    "\n",
    "\n",
    "In this homework, we're going to explore the Federal Election\n",
    "Commission's data on the money exchanged during the 2016 election.\n",
    "\n",
    "This homework has two main parts:\n",
    "\n",
    "1. Answering questions and computing descriptive statistics on the data\n",
    "2. Conducting a hypothesis test\n",
    "\n",
    "This is very similar to what you've done before in this class. However, in this\n",
    "homework almost all of our computations will be done using SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "For this assignment, you're going to use a popular cloud services provider: Heroku. This will give you some experience provisioning a database in the cloud and working on that database from your computer.\n",
    "\n",
    "Since the free tier of Heroku's Postgres service limits users to 10,000 rows of data, we've provided a subset of the FEC dataset for you to work with.\n",
    "\n",
    "If you're interested, you can download and load the entire dataset from\n",
    "http://www.fec.gov/finance/disclosure/ftpdet.shtml.  It is about 4GB and contains around 24 million rows. (With Heroku and other cloud services, it is relatively straightforward to rent clusters of machines to work on much larger datasets.  In particular, it would be easy to rerun your analyses in this assignment on the full dataset.)\n",
    "\n",
    "## If you've already done this for lab08, you do not have to follow these steps again. Otherwise you can get duplicate data in your database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provisioning the Postgres DB\n",
    "\n",
    "1. Visit https://signup.heroku.com/postgres-home-button and sign up for an account\n",
    "if you don't have one already.\n",
    "2. Now, install the Heroku CLI: https://devcenter.heroku.com/articles/heroku-cli.\n",
    "Then, run `heroku login` to log into Heroku from your CLI.\n",
    "3. Now, visit https://dashboard.heroku.com/apps and click **New -> App**. Name the app\n",
    "whatever you want.\n",
    "4. You should be sent to the app details page. Click **Resources** in the navbar, then\n",
    "in the **Add-on** search bar, type \"Postgres\". You should be able to select **Heroku\n",
    "Postgres**. Make sure the free tier (**Hobby Dev**) is selected and click **Provision**. Now\n",
    "you should see **Heroku Postgres :: Database** in your **Add-ons** list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data into the Heroku DB\n",
    "\n",
    "(1) Run the lines below in your terminal to install necessary libraries. (If you're running the jupyter notebook in the ds100 environment, the following 3 commands need to be ran in ds100 environment as well)\n",
    "\n",
    "    conda install -y psycopg2\n",
    "    conda install -y postgresql\n",
    "    pip install ipython-sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Click the **Heroku Postgres :: Database** link in your app's **Add-ons** list.\n",
    "\n",
    "(3) In the **Heroku Data** page you got redirected to, you should see the name of your\n",
    "database. You can click on the **Setting** panel, then scroll down to **Administration** and click **View Credentials**. These are the\n",
    "credentials that allow you to connect to the database. The last entry of the list\n",
    "contains a line that looks like:\n",
    "\n",
    "        heroku pg:psql db_name --app app_name\n",
    "\n",
    " In your terminal, take that command and add \"`< fec.sql`\" to the end\n",
    " to get something like: (You need to run this command in the folder which contains the fec.sql file. The file comes with the zip file of this homework)  \n",
    "\n",
    "### ** Make sure you only run this ONCE, if you did it for lab, don't do it for homework**\n",
    "\n",
    "        heroku pg:psql db_name --app app_name < fec.sql\n",
    "        \n",
    "        \n",
    " Run that command. It will run the commands in `fec.sql`, which load the dataset into the database.\n",
    " Now you should be able to run the command without the \"`< fec.sql`\" to\n",
    " have a postgres prompt. Try typing \"`\\d+`\" at the prompt. You should get\n",
    " something like:\n",
    "     \n",
    "        ds100-hw4-db::DATABASE=> \\d+\n",
    "                               List of relations\n",
    "         Schema |           Name           |   Type   |     Owner\n",
    "        --------+--------------------------+----------+----------------\n",
    "         public | cand                     | table    | vibrgrsqevmzkj\n",
    "         public | comm                     | table    | vibrgrsqevmzkj\n",
    "         public | ds100grades              | table    | vibrgrsqevmzkj\n",
    "         public | ds100grades_recordid_seq | sequence | vibrgrsqevmzkj\n",
    "         public | ds100weights             | table    | vibrgrsqevmzkj\n",
    "         public | indiv_sample             | table    | vibrgrsqevmzkj\n",
    "         public | indiv_sample_top         | table    | vibrgrsqevmzkj\n",
    "         public | students                 | table    | vibrgrsqevmzkj\n",
    "        (8 rows)\n",
    "\n",
    "Congrats! You now have a Postgres database running containing the data you need\n",
    "for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# For instructor use only. Call this function to force refresh okpy tests\n",
    "def refresh():\n",
    "    import sys\n",
    "    keys = [k for k in sys.modules.keys() if 'ok_tests' in k]\n",
    "    for k in keys:\n",
    "        del sys.modules[k]\n",
    "    global ok\n",
    "    ok = Notebook('hw5.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "sns.set()\n",
    "\n",
    "!pip install -U okpy\n",
    "from client.api.notebook import Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = Notebook('hw5.ok')\n",
    "ok.auth(force=False) # Change False to True if you are getting errors authenticating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's connect to your Postgres database. On your Heroku Postgres details,\n",
    "look at the credentials for the database. Take the long URI in the credentials and\n",
    "replace the portion of the code that reads `\"replace_me\"` with the URI.\n",
    "\n",
    "It should start with `postgres://`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "scrolled": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "my_URI = \"postgres://vibrgrsqevmzkj:79d76ebb9ae05f3e4a2eeb9397aa325dddf88932ffca0e6e568db9f8ea6466e4@ec2-54-243-214-198.compute-1.amazonaws.com:5432/ddfrb6gftpi2oa\"\n",
    "#my_URL = \"postgres://postgres:7Rgg07yrpAB0@13.66.222.248/fec\"\n",
    "%load_ext sql\n",
    "%sql $my_URI\n",
    "engine = sqlalchemy.create_engine(my_URI)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Descriptions\n",
    "\n",
    "Here is a list of the tables in the database.  Each table links to the documentation on the [FEC page](http://www.fec.gov/finance/disclosure/ftpdet.shtml) for the dataset.\n",
    "\n",
    "Note that the table names here are slightly different from the ones in lecture. Consult the FEC page\n",
    "for the descriptions of the tables to find out what the correspondence is.\n",
    "\n",
    "- [`cand`](http://www.fec.gov/finance/disclosure/metadata/DataDictionaryCandidateMaster.shtml): Candidates table. Contains names and party affiliation.\n",
    "- [`comm`](http://www.fec.gov/finance/disclosure/metadata/DataDictionaryCommitteeMaster.shtml): Committees table. Contains committee names and types.\n",
    "- [`indiv_sample`](http://www.fec.gov/finance/disclosure/metadata/DataDictionaryContributionsbyIndividuals.shtml): Sample of individual contributions from Berkeley.\n",
    "- [`indiv_sample_top`](http://www.fec.gov/finance/disclosure/metadata/DataDictionaryContributionsbyIndividuals.shtml): Sample of individual contributions from the top contributors at Berkeley.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing SQL queries\n",
    "\n",
    "You can write SQL directly in the notebook by using the `%sql` magic, as demonstrated in the next cell.\n",
    "\n",
    "Be careful when doing this.\n",
    "If you try to run a SQL query that returns a lot of rows (100k or more is a good rule of thumb)\n",
    "your browser will probably crash.\n",
    "\n",
    "This is why in this homework, we will strongly prefer using SQL as much as\n",
    "possible, only materializing the SQL queries when they are small.\n",
    "\n",
    "**Because of this, your queries should work even as the size of your\n",
    "data goes into the terabyte range! This is the primary advantage of working\n",
    "with SQL as opposed to only dataframes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use `LIMIT 5` to avoid displaying a huge table.\n",
    "# Although our tables shouldn't get too large to display,\n",
    "# this is generally good practice when working in the\n",
    "# notebook environment.  Jupyter notebooks don't handle\n",
    "# very large outputs well. \n",
    "%sql SELECT * from indiv_sample LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For longer queries, you can save your query into a string, then use it in the\n",
    "`%sql` statement. The `$query` in the `%sql` statement pulls in the value in\n",
    "the Python variable `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT cand_id, cand_name\n",
    "FROM cand\n",
    "WHERE cand_pty_affiliation = 'DEM'\n",
    "LIMIT 5\n",
    "'''\n",
    "\n",
    "%sql $query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, you can assign the SQL statement to a variable and then call `.DataFrame()` on it to get a Pandas DataFrame.  \n",
    "\n",
    "However, it will often be more efficient to express your computation directly in SQL.  For this homework, we will be grading your SQL expressions so be sure to do all computation in SQL (unless otherwise requested)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = %sql select * from cand limit 5\n",
    "res_df = res.DataFrame()\n",
    "res_df['cand_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1a\n",
    "\n",
    "We are interested in finding the individuals from Berkeley that donated large sums. To begin to answer this question, we will look at the `indiv_sample` table. We'll find all the transactions that exceed \\$3,000. However, if there are a lot of transactions like that, it might not be useful to list them all.  So before actually finding the transactions, find out how many such transactions there are. Use only SQL to compute the answer.\n",
    "\n",
    "(It should be a table with a single column called **`count`** and a single entry, the number of transactions.)  \n",
    "\n",
    "We will be grading the query string `query_q1a`.  You may modify our template but the result should contain the same information with the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "solution",
     "q01a"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q1a = '''\n",
    "SELECT count(*)\n",
    "FROM indiv_sample\n",
    "WHERE transaction_amt > 3000\n",
    "'''\n",
    "q1a = %sql $query_q1a\n",
    "q1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "q01a",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "assert connection.execute(query_q1a).fetchall() == [(4,)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b\n",
    "Having seen that there aren't too many transactions that exceed \\$3,000, let's find them all.  Using only SQL, construct a table containing the committee ID, contributor's name, and the transaction amount, for transactions that exceed $3,000 dollars.  Sort the transactions in decreasing order by amount. If two contributors contain the same transaction amount, sort by alphabetical order of their names.\n",
    "\n",
    "We will be grading the query string `query_q1b`.  You may modify our template but the result should contain the same information with the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "solution",
     "q01b"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q1b = '''\n",
    "SELECT \n",
    "    cmte_id AS committee_id, \n",
    "    name AS name,\n",
    "    transaction_amt AS transaction_amt\n",
    "FROM indiv_sample\n",
    "WHERE transaction_amt > 3000\n",
    "ORDER BY transaction_amt DESC, name\n",
    "'''\n",
    "q1b = %sql $query_q1b\n",
    "q1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q01b"
    ]
   },
   "outputs": [],
   "source": [
    "expected = [('C00586537', 'GUND, LOUISE LAIDLAW', 25000), ('C00000935', 'FIDDLER, JERRY', 10000), ('C00586537', 'LAPPEN, DAVID', 5000), ('C00401224', 'LUEVANO, ROSA', 5000)]\n",
    "assert connection.execute(query_q1b).fetchall() == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1c\n",
    "Of course, only looking at individual transactions could be misleading, since each contributor can make several transactions. A more interesting question is: How much did each contributor give *in total*?  Find the total transaction amounts after grouping by the name.  This time, just use `LIMIT 20` to limit your results to the top 20 total donations. Sort the results in descending order by total contribution amount. Break ties by alphabetical order of name as in the previous question.\n",
    "\n",
    "Do you see any names that are familiar?\n",
    "\n",
    "We will be grading the query string `query_q1c`.  You may modify our template but the result should contain the same information with the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "solution",
     "q01c"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q1c = '''\n",
    "SELECT \n",
    "    name AS name, \n",
    "    sum(transaction_amt) AS total_transaction_amt \n",
    "FROM indiv_sample \n",
    "GROUP BY name\n",
    "ORDER BY total_transaction_amt DESC, name\n",
    "LIMIT 20\n",
    "'''\n",
    "q1c = %sql $query_q1c\n",
    "q1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q01c"
    ]
   },
   "outputs": [],
   "source": [
    "expected = [('GUND, LOUISE LAIDLAW', 25000), ('FIDDLER, JERRY', 10000), ('SHENKER, SCOTT', 8000), ('BERLEKAMP, ELWYN', 5550), ('ABRAMS, DENISE', 5400), ('LAPPEN, DAVID', 5000), ('LUEVANO, ROSA', 5000), ('BERNHARDT, ANTHONY', 3200), ('HUFF, GERALD', 3200), ('BIRD, KAREN', 2700), ('EPSTEIN, BOB', 2700), ('HAHN, SOPHIE', 2700), ('JOSEPH, DAVID', 2700), ('LITTMANN, NICOLE', 2700), ('LOGAN, JONATHAN', 2700), ('REINIS, JONATHAN ROY', 2700), ('SEIBEL, PETER', 2700), ('SHAPIRO, CARL', 2700), ('TAYLOR, JEROME', 2700), ('WILNER, DAVID', 2700)]\n",
    "assert connection.execute(query_q1c).fetchall() == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2a\n",
    "\n",
    "Another interesting thing is to see what is the distribution of contributors by occupation? Let's first compute how many distinct occupations occur in the dataset. You may need to use the `DISTINCT` keyword to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q02a"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q2a = '''\n",
    "SELECT \n",
    "    COUNT(distinct occupation)\n",
    "FROM indiv_sample \n",
    "'''\n",
    "q2a = %sql $query_q2a\n",
    "q2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "q02a",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "assert connection.execute(query_q2a).fetchall() == [(407,)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b \n",
    " Write a SQL query which computes for each occupation the number of transactions in the indiv_sample table. Display the top 20 results in descending order by count. \n",
    "\n",
    "We will be grading the query string `query_q2b`.  You may modify our template but the result should contain the same information with the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "solution",
     "q02b"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q2b = '''\n",
    "SELECT \n",
    "    occupation AS occupation, \n",
    "    count(*) AS count\n",
    "FROM indiv_sample \n",
    "GROUP BY occupation\n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "'''\n",
    "q2b = %sql $query_q2b\n",
    "q2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "q02b",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "expected = [('NOT EMPLOYED', 373), ('RETIRED', 306), (None, 70), ('PROFESSOR', 58), ('ATTORNEY', 56), ('NONE', 33), ('SCIENTIST', 30), ('RETIRED TEACHER', 20), ('ENGINEER', 20), ('PHONE CLERK', 20), ('ARTIST', 19), ('PSYCHOLOGIST', 19), ('HOMEMAKER', 19), ('UNEMPLOYED', 18), ('WRITER', 18), ('PHYSICIAN', 18), ('TEACHER', 17), ('LAWYER', 16), ('PSYCHOTHERAPIST', 16), ('PROFESSIONAL', 15)]\n",
    "assert connection.execute(query_q2b).fetchall()[:6] == expected[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 2c\n",
    "Compute the average transaction amount for each occupation, and sort them in descending order. Display the top 10 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q02c"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q2c = '''\n",
    "SELECT \n",
    "    occupation AS occupation, \n",
    "    avg(transaction_amt) AS amount,\n",
    "    count(*) AS count\n",
    "FROM indiv_sample \n",
    "GROUP BY occupation \n",
    "ORDER BY amount DESC\n",
    "LIMIT 10\n",
    "'''\n",
    "q2c = %sql $query_q2c\n",
    "q2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q02c"
    ]
   },
   "outputs": [],
   "source": [
    "func = lambda x:list(map(lambda y:(y[0],int(y[1]),y[2]),x))\n",
    "expected = [('LOUISE GUND FOUNDATION', 25000, 1), ('INVESTOR/BOARD MEMBER', 10000, 1), ('MARRIAGE & FAMILY THERAPIST', 5000, 1), ('INVESTMENT MANAGEMENT', 2700, 1), ('LIVE THEATRE PRODUCER', 2700, 1), ('CHAIRMAN', 2700, 1), ('AIDS CASE MANAGER', 2500, 1), ('WEALTH MANAGER', 1700, 1), ('INVESTOR', 1485, 2), ('ACCOUNTANT', 1475, 2)]\n",
    "assert func(connection.execute(query_q2c).fetchall())[:3] == expected[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 2d\n",
    "You may find that the top results only contains 1 or 2 transaction which are not useful. So we should only keep the reulsts that have more than 10 transcations. This time, you should use a nested `SELECT` to apply the filter on the results from q2c. After that, display the top 10 occupations that mave the largest average transaction amount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q02d"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q2d = '''\n",
    "SELECT \n",
    "    occupation AS occupation, \n",
    "    amount AS amount,\n",
    "    count AS count\n",
    "FROM\n",
    "    (SELECT \n",
    "        occupation AS occupation, \n",
    "        avg(transaction_amt) AS amount,\n",
    "        count(*) AS count\n",
    "    FROM indiv_sample \n",
    "    GROUP BY occupation \n",
    "    ORDER BY amount DESC) AS t\n",
    "WHERE count > 10\n",
    "LIMIT 10\n",
    "'''\n",
    "q2d = %sql $query_q2d\n",
    "q2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q02d"
    ]
   },
   "outputs": [],
   "source": [
    "func = lambda x:list(map(lambda y:(y[0],int(y[1]),y[2]),x))\n",
    "expected = [('ATTORNEY', 423, 56), ('SOFTWARE ENGINEER', 371, 13), ('CONSULTANT', 343, 12), ('STUDENT', 317, 11), ('SCIENTIST', 298, 30), ('ENGINEER', 228, 20), ('ARTIST', 216, 19), ('PHYSICIAN', 193, 18), ('RETIRED', 143, 306), ('UNEMPLOYED', 140, 18)]\n",
    "assert func(connection.execute(query_q2d).fetchall()) == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 2e\n",
    "In the previous queries, we compute the average transaction amount. But since each contributor can make several transactions, this doesn't tell us much. In stead, we should compute the average amount that a contributor made for each type of occupation. To achieve this, let's first group the transactions by name to compute the total amount for each individual, which is similar to q1c. But this time, we should `SELECT` the occupation as well. Display the top 10 results order by total_amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q02e"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q2e = '''\n",
    "SELECT \n",
    "    occupation AS occupation,\n",
    "    name AS name,\n",
    "    sum(transaction_amt) AS total_amount\n",
    "FROM indiv_sample\n",
    "GROUP BY occupation,name\n",
    "ORDER BY total_amount DESC\n",
    "LIMIT 10\n",
    "'''\n",
    "q2e = %sql $query_q2e\n",
    "q2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q02e"
    ]
   },
   "outputs": [],
   "source": [
    "func = lambda x:list(map(lambda y:(y[0],y[1],int(y[2])),x))\n",
    "expected = [('LOUISE GUND FOUNDATION', 'GUND, LOUISE LAIDLAW', 25000), ('INVESTOR/BOARD MEMBER', 'FIDDLER, JERRY', 10000), ('SCIENTIST', 'SHENKER, SCOTT', 8000), ('RETIRED', 'BERLEKAMP, ELWYN', 5550), ('ATTORNEY', 'ABRAMS, DENISE', 5400), ('NOT EMPLOYED', 'LUEVANO, ROSA', 5000), ('MARRIAGE & FAMILY THERAPIST', 'LAPPEN, DAVID', 5000), ('SOFTWARE ENGINEER', 'HUFF, GERALD', 3200), ('RETIRED', 'BERNHARDT, ANTHONY', 3200), ('MANAGER', 'SEIBEL, PETER', 2700)]\n",
    "assert func(connection.execute(query_q2e).fetchall())[:5] == expected[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2f\n",
    "Let's continue with 2e, after computing the total amount for each individual. We can compute the average total_amount for each occupation type. Again, we should filter out the occupations that have small counts. Therefore, you should only select the top 10 occupations order by the average total_amount, with the constrains that the number of contributors in that occupation should be large than 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q02f"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q2f = '''\n",
    "SELECT occupation,amount,count\n",
    "FROM\n",
    "    (SELECT \n",
    "        occupation,\n",
    "        avg(total_amount) as amount,\n",
    "        count(*) as count\n",
    "    FROM\n",
    "        (SELECT \n",
    "            occupation,\n",
    "            sum(transaction_amt) AS total_amount\n",
    "        FROM indiv_sample \n",
    "        GROUP BY occupation,name \n",
    "        ) AS t\n",
    "        GROUP BY occupation\n",
    "        ORDER BY amount DESC\n",
    "    ) AS t2\n",
    "WHERE count > 5\n",
    "LIMIT 10\n",
    "'''\n",
    "q2f = %sql $query_q2f\n",
    "q2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q02f"
    ]
   },
   "outputs": [],
   "source": [
    "func = lambda x:list(map(lambda y:(y[0],int(y[1]),y[2]),x))\n",
    "expected = [('SCIENTIST', 1118, 8), ('ATTORNEY', 593, 40), ('SOFTWARE ENGINEER', 535, 9), ('CONSULTANT', 374, 11), ('STUDENT', 349, 10), ('NOT-EMPLOYED', 331, 9), ('ARTIST', 273, 15), ('PHYSICIAN', 268, 13), ('ENGINEER', 253, 18), ('PROFESSOR', 240, 32)]\n",
    "assert func(connection.execute(query_q2f).fetchall()) == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Now let's examine the committees that appear in the `indiv_sample` table, with the information from the `comm` table. First let's take a look of the `comm` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from comm limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 3a\n",
    "Let's first groupby the transactions in the `indiv_sample` table with `cmte_id` column (committee id), then count how many transactions and how much total amount of contribution there are for each `cmte_id`. Select the top 5 committee id order by the transactions count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q03a"
    ]
   },
   "outputs": [],
   "source": [
    "query_q3a='''\n",
    "SELECT\n",
    "    cmte_id AS committee_id,\n",
    "    sum(transaction_amt) AS total_amount,\n",
    "    count(*) AS count\n",
    "FROM indiv_sample\n",
    "GROUP BY cmte_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "'''\n",
    "q3a = %sql $query_q3a\n",
    "q3a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q03a"
    ]
   },
   "outputs": [],
   "source": [
    "expected = [('C00401224', 66228, 799), ('C00575795', 38002, 252), ('C00577130', 19920, 239), ('C00000935', 26040, 153), ('C00042366', 7271, 71)]\n",
    "assert connection.execute(query_q3a).fetchall() == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 3b\n",
    "Only showing the committee id doesn't tell us much. Let's also select the committee information by joining with the `comm` table using the `cmite_id` field.\n",
    "\n",
    "You will extend the query we have from q3a and then perform a `JOIN` with the `comm` table. Select extra committee information such as committee name, party_affiliation, city and state from `comm`. Select the top 10 committees order by transaction count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q03b"
    ]
   },
   "outputs": [],
   "source": [
    "query_q3b = '''\n",
    "WITH cmte_count AS\n",
    "(\n",
    "  SELECT \n",
    "      cmte_id AS cmte_id,\n",
    "      sum(transaction_amt) AS total_amount,\n",
    "      count(*) AS count\n",
    "  FROM indiv_sample \n",
    "  GROUP BY cmte_id \n",
    ")\n",
    "SELECT \n",
    "    c.cmte_nm AS cmte_name, \n",
    "    c.cmte_pty_affiliation AS party_affiliation,\n",
    "    c.cmte_city AS city,\n",
    "    c.cmte_st AS state,\n",
    "    i.total_amount AS total_amount,\n",
    "    i.count AS count\n",
    "FROM comm c RIGHT OUTER JOIN cmte_count i ON c.cmte_id = i.cmte_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 10\n",
    "'''\n",
    "q3b = %sql $query_q3b\n",
    "q3b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q03b"
    ]
   },
   "outputs": [],
   "source": [
    "expected = [('ACTBLUE', None, 'SOMERVILLE', 'MA', 66228, 799), ('HILLARY FOR AMERICA', 'DEM', 'NEW YORK', 'NY', 38002, 252), ('BERNIE 2016', 'DEM', 'BURLINGTON', 'VT', 19920, 239), ('DCCC', 'DEM', 'WASHINGTON', 'DC', 26040, 153), ('DSCC', 'DEM', 'WASHINGTON', 'DC', 7271, 71), ('END CITIZENS UNITED', None, 'WASHINGTON', 'DC', 1129, 47), ('HILLARY VICTORY FUND', None, 'NEW YORK', 'NY', 44163, 45), ('MOVEON.ORG POLITICAL ACTION', None, 'WASHINGTON', 'DC', 2836, 37), ('CATHERINE CORTEZ MASTO FOR SENATE', 'DEM', 'LAS VEGAS', 'NV', 6878, 27), (\"EMILY'S LIST\", None, 'WASHINGTON', 'DC', 7988, 26)]\n",
    "assert connection.execute(query_q3b).fetchall() == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3c\n",
    "From the results in q3b, it seems most of the party affiliation are DEM. So let's count the actual distribution of the party affiliation. Select all the different committee id from `indiv_sample`, joining with the `comm` table. Then group the results by party_affiliation and count how many committees there are for each party_affiliation. Order the results by committee count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q03c"
    ]
   },
   "outputs": [],
   "source": [
    "query_q3c = '''\n",
    "WITH cmte AS\n",
    "(\n",
    "  SELECT \n",
    "      DISTINCT cmte_id AS cmte_id\n",
    "  FROM indiv_sample \n",
    ")\n",
    "SELECT \n",
    "    c.cmte_pty_affiliation AS party_affiliation,\n",
    "    count(*) AS count\n",
    "FROM comm c  RIGHT OUTER JOIN cmte i ON c.cmte_id = i.cmte_id\n",
    "GROUP BY c.cmte_pty_affiliation\n",
    "ORDER BY count DESC\n",
    "'''\n",
    "q3c = %sql $query_q3c\n",
    "q3c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q03c"
    ]
   },
   "outputs": [],
   "source": [
    "expected = [('DEM', 58), (None, 44), ('REP', 8), ('UNK', 4), ('NNE', 2), ('GRE', 1)]\n",
    "assert connection.execute(query_q3c).fetchall() == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: A Permutation Test in SQL\n",
    "\n",
    "In this part, we're going to perform a hypothesis test using a permutation test. We'll perform nearly all our operations in SQL.\n",
    "\n",
    "Here's our question: **Is there a difference in the proportion of donations made by small donors (under \\$200) in Berkeley to Hillary Clinton's and Bernie Sanders' campaigns?**\n",
    "\n",
    "**Probability Model:** To formulate a null hypothesis, we must consider the how the data are generated, i.e., we need to have a probability model for how the data arose.  We know that the sample was taken at random from the collection of all donations from Berkeley donors. We argue that Clinton attracts small donors at the same rate as Sanders. Then, given the proportion of donors in the combined sample of Clinton and Sanders donors, it's  just by chance that the proportion for Sanders and the proportion for Clinton don't match. \n",
    "\n",
    "With this model, we can figure out (approximate) the probability that the difference between these proportions would be as large or larger than the observed difference. To do this, we use a permuation test. \n",
    "\n",
    "**Permutation Test:**  In the permuation test, we simply mix up the small and large donors, and then tally the number of small donors to Clinton and the number to Sanders. We keep both the total number of donors to Clinton and the total number of donors to Sanders the same as in the sample, and we compare the two proportions by taking their difference. Essentially, we can think of this mixing as permuting the labels (\"Clinton donor\" and \"Sanders donor\") on all of the donors in our sample. For each random permutation, we tally the proportion of small donors to Clinton and Sanders and take their difference. After many permutations, we can examine the distribution of differences to see how likely it was to have observed our sample's difference. \n",
    "\n",
    "**Formal Hypothesis:** Now that we have a better understanding of the probability model, we formulate the null hypotheis as follows:\n",
    "\n",
    "**$H_o$:** Clinton and Sanders attract the same proportion of small donors. Any observed difference in our sample is simply due to chance variation.\n",
    "\n",
    "**$H_A$:**  The difference is real. \n",
    "\n",
    "Note: We might consider a *one-sided* alternative in this siutation. A one-sided alternative would be that Sanders' proportion is larger than Clinton's. Why would we do this?  Sanders made it part of his campaign that he was funded entirely by small donoations and that he wasn't obligated to `big money.' For this reason, we might be interested only in the side that shows Sanders having a greater proportion than Clinton, and not vice versa. \n",
    "\n",
    "For a review of permutation tests, we suggest looking over [this section on A/B testing](https://www.inferentialthinking.com/chapters/16/2/ab-testing.html) from the Data 8 textbook. Lecture #13 on Hypothesis testing includes an example of a permutation test. \n",
    "\n",
    "\n",
    "In this part, our skeletons will be minimal; it is your responsibility to use the right statements to answer the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Before we begin, please think about and answer the following questions.\n",
    "\n",
    "**For each question, state \"Yes\" or \"No\", followed by a one-sentence explanation.**\n",
    "\n",
    "**(a)** If we were working with the entire FEC dataset instead of a sample,\n",
    "would we still conduct a hypothesis test? Why or why not?\n",
    "\n",
    "**(b)** Let's suppose we find that in our sample the difference in the proportion of money coming from\n",
    "small donations by Berkeley donors to Hillary and Bernie's campaign is 0.3. Would\n",
    "we still need to conduct a hypothesis test? Why or why not?\n",
    "\n",
    "**(c)** Let's suppose we find that in our sample the difference in the proportion of money coming from\n",
    "small donations by Berkeley donors to Hillary and Bernie's campaign is 0. Would\n",
    "we still need to conduct a hypothesis test? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "solution",
     "written",
     "q04"
    ]
   },
   "source": [
    "**Solution:**\n",
    "\n",
    "**(a)** No. If we had the entire dataset, we could directly compute the\n",
    "difference in proportion. Since the dataset contains **all** transactions,\n",
    "we have the entire population we care about.\n",
    "\n",
    "**(b)** Yes. Even though our *sample difference* is large, we would want to carry out the test and compute the chance of such a large or larger difference under the hypothesis that the true difference of 0. In this case, we will most likely reject the null hypothesis, but we want to find the $p$-value to confirm.\n",
    "\n",
    "**(c)** No. Given our *sample difference* matches the hypothesized difference for the population, we know that we would not reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "As discussed, we've taken a simple random sample of 2000 rows of the original FEC data for individual contributions that only include contributions from Berkeley. This sample is stored in the table `indiv_sample`.\n",
    "\n",
    "The individual contributions of donors are linked to committees, not candidates directly. Hillary's primary committee was called `HILLARY FOR AMERICA`, and Bernie's was `BERNIE 2016`.\n",
    "\n",
    "Fill in the SQL query below to compute a SQL view called `contribs` of all the contributions for each\n",
    "candidate's committee. Views are like tables. However, instead of storing the rows in the database, Postgres will recompute the values in the view each time you query it.\n",
    "\n",
    "The resulting view should contain three columns:\n",
    "\n",
    "1. `name`: The names of the each contributor\n",
    "2. `transaction_amt`: The amount of each contribution\n",
    "3. `cmte_nm`: The name of the committee that received the contribution (either `HILLARY FOR AMERICA` or `BERNIE 2016`).\n",
    "\n",
    "Order your result by `transaction_amt` in descending order, breaking ties using `name` in alphabetical order.\n",
    "\n",
    "We will be grading you on the query string `query_q5`.  You may modify our template but the result should contain the same information with the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "query_q5 = \"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW contribs AS\n",
    "SELECT i.name, i.transaction_amt, c.cmte_nm\n",
    "FROM indiv_sample AS i, comm AS c\n",
    "WHERE i.cmte_id = c.cmte_id\n",
    "    AND (c.cmte_nm = 'HILLARY FOR AMERICA'\n",
    "         OR c.cmte_nm = 'BERNIE 2016')\n",
    "ORDER BY transaction_amt DESC, name\n",
    "\"\"\"\n",
    "\n",
    "%sql DROP VIEW IF EXISTS contribs CASCADE\n",
    "%sql $query_q5\n",
    "%sql SELECT * FROM contribs LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q05"
    ]
   },
   "outputs": [],
   "source": [
    "expected = [('HAHN, SOPHIE', 2700, 'HILLARY FOR AMERICA'), ('JOSEPH, DAVID', 2700, 'HILLARY FOR AMERICA'), ('LITTMANN, NICOLE', 2700, 'BERNIE 2016'), ('LOGAN, JONATHAN', 2700, 'BERNIE 2016'), ('REINIS, JONATHAN ROY', 2700, 'HILLARY FOR AMERICA')]\n",
    "r=connection.execute(\"DROP VIEW IF EXISTS contribs CASCADE\")\n",
    "r=connection.execute(query_q5)\n",
    "assert connection.execute(\"SELECT * FROM contribs LIMIT 5\").fetchall() == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the maximum donation is \\$2700. See if you can use Google to find out why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Use the `sample` view to fill in the SQL query below to compute a table containing three columns:\n",
    "\n",
    "- `cmte_nm`: The committee name\n",
    "- `small`: The number of small donors to that committee\n",
    "- `total`: The total number of donors to that committee\n",
    "\n",
    "The resulting table should have this structure (your counts will not exactly match these):\n",
    "\n",
    "<table>\n",
    "    <tbody><tr>\n",
    "        <th>cmte_nm</th>\n",
    "        <th>small</th>\n",
    "        <th>total</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>BERNIE 2016</td>\n",
    "        <td>1</td>\n",
    "        <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>HILLARY FOR AMERICA</td>\n",
    "        <td>2</td>\n",
    "        <td>4</td>\n",
    "    </tr>\n",
    "</tbody></table>\n",
    "\n",
    "Then, uncomment the provided line of code to load the query into a DataFrame. Use the DataFrame to compute our observed statistic:\n",
    "\n",
    "$$ \\frac {\\textrm{total donations under \\$200 to Hillary}} {\\textrm{total donations to Hillary}} - \n",
    "    \\frac {\\textrm{total donations under \\$200 to Bernie}} {\\textrm{total donations to Bernie}}. \n",
    "$$\n",
    "\n",
    "Then, save the numerical value in the variable `observed_stat`.\n",
    "\n",
    "Hint: We suggest computing the total amounts donated to each candidate using a WITH clause, then using the resulting table to compute the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "solution",
     "q06"
    ]
   },
   "outputs": [],
   "source": [
    "query_q6 = '''\n",
    "WITH marked AS (\n",
    "    SELECT *,\n",
    "        (CASE WHEN transaction_amt <= 200\n",
    "        THEN 1 ELSE 0\n",
    "        END) AS small\n",
    "    FROM contribs\n",
    ")\n",
    "SELECT cmte_nm, SUM(small) AS small, COUNT(*) AS total\n",
    "FROM marked\n",
    "GROUP BY cmte_nm\n",
    "ORDER BY cmte_nm\n",
    "'''\n",
    "\n",
    "q6_df = pd.DataFrame(connection.execute(query_q6).fetchall(), columns=['cmte_nm', 'small', 'total'])\n",
    "\n",
    "proportions = (q6_df['small'] / q6_df['total'])\n",
    "observed_stat = proportions[1] - proportions[0]\n",
    "observed_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q06"
    ]
   },
   "outputs": [],
   "source": [
    "expected = [('BERNIE 2016', 212, 239), ('HILLARY FOR AMERICA', 225, 252)]\n",
    "assert connection.execute(query_q6).fetchall() == expected\n",
    "assert np.allclose(observed_stat, 0.0058278541542140516)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this result surprising?  Even though the difference is quite small, this difference could still be considered large relative to the standard error of the statistic. We need to find the chance of a difference this large or larger under the null hypothesis.  That's where our permutation test comes into the picture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conducting a Permutation Test\n",
    "\n",
    "As mentioned above, in a permutation test, we generate new observations as follows: \n",
    "\n",
    "1. Shuffle the observed values between the two samples. In this case, shuffle the contributions between Hillary and Bernie. We do this because we assume that our null hypothesis is true and that it was just by chance that Clinton had a higher proportion of small donors than Sanders. \n",
    "2. Recompute the test statistic on the shuffled sample.\n",
    "3. Repeat.\n",
    "\n",
    "To do this in SQL, we need to number the rows we want to bootstrap.\n",
    "\n",
    "The following cell creates a view called `sample`.\n",
    "\n",
    "It adds a `row_id` column to each row in `contribs` corresponding to a contribution and removes the `name` column since we don't need it for the permutation test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Let's contruct a view containing the shuffled `row_id`'s for each trial. For example, if we had 3 contributions total and wanted to create 100 shuffled samples, we want something that looks like:\n",
    "\n",
    "```\n",
    "trial_id | row_id\n",
    "======== | ======\n",
    "1        | 1\n",
    "1        | 3\n",
    "1        | 2\n",
    "2        | 2\n",
    "2        | 1\n",
    "2        | 3\n",
    "...      | ...\n",
    "100      | 2\n",
    "100      | 3\n",
    "100      | 1\n",
    "```\n",
    "\n",
    "This will let us later construct a join on the `sample` view that computes the\n",
    "shuffled sample for each trial.\n",
    "\n",
    "Create a view called `design` that contains two columns: `trial_id`\n",
    "and `row_id`. It should contain the IDs corresponding to\n",
    "1000 reshuffles of the entire `sample` view. The `sample` view contains 491\n",
    "rows, so the `design` view should have a total of\n",
    "`1000 * 491 = 491000` rows.\n",
    "\n",
    "Hint: See if you can generate the trial_id and row_id in sorted order first. Then, try to shuffle the rows within each `trial_id` using a clever ORDER BY clause. We've done something similar in class when we took a sample without replacement in SQL. Our solution uses the Postgres functions `generate_series` and `random()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "q07"
    ]
   },
   "outputs": [],
   "source": [
    "# You may use these variables in your SQL query by prefixing the variable name with $\n",
    "# eg. $n_trials\n",
    "n_rows = 491\n",
    "n_trials = 1000\n",
    "\n",
    "query_q7 = \"\"\"\n",
    "CREATE VIEW design AS\n",
    "SELECT *\n",
    "FROM GENERATE_SERIES(1, $n_trials) as trial_id,\n",
    "    GENERATE_SERIES(1, $n_rows) as row_id\n",
    "ORDER BY trial_id, RANDOM()\n",
    "\"\"\"\n",
    "\n",
    "# Do not change anything below this line\n",
    "\n",
    "# Fill in the $ variables set in the above string\n",
    "import string\n",
    "query_q7 = string.Template(query_q7).substitute(locals())\n",
    "\n",
    "seed = 0.42\n",
    "%sql drop view if exists design cascade\n",
    "%sql SET SEED TO $seed\n",
    "%sql $query_q7\n",
    "%sql select * from design limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q07"
    ]
   },
   "outputs": [],
   "source": [
    "r=connection.execute(\"drop view if exists design cascade\")\n",
    "r=connection.execute(\"SET SEED TO \" + str(seed))\n",
    "r=connection.execute(query_q7)\n",
    "# Test that your view has the right length\n",
    "assert connection.execute(\"select count(*) from design\").fetchall() == [(491000,)]\n",
    "# If you fail these tests, you aren't shuffling the rows within each group only\n",
    "assert connection.execute(\"select SUM(row_id) from design where trial_id = 1\").fetchall() == [(120786,)]\n",
    "assert connection.execute(\"select SUM(row_id) from design where trial_id = 2\").fetchall() == [(120786,)]\n",
    "assert connection.execute(\"select SUM(row_id) from design where trial_id = 3\").fetchall() == [(120786,)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Construct a view called `joined` that uses the `sample` and `design` views to create a table containing the shuffled transaction amounts along with the **unshuffled** committee names — the committee names in the same order as they appeared in the original sample. Remember that in the permutation test we are shuffling the transaction amounts between the committees.\n",
    "\n",
    "It should have three columns:\n",
    "\n",
    "- `trial_id`: The number of the trial, from 1 to 10000\n",
    "- `transaction_amt`: The shuffled transaction amounts\n",
    "- `cmte_nm`: The **unshuffled** committee names.\n",
    "\n",
    "It should look something like:\n",
    "\n",
    "<table>\n",
    "    <tbody><tr>\n",
    "        <th>trial_id</th>\n",
    "        <th>transaction_amt</th>\n",
    "        <th>cmte_nm</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>10</td>\n",
    "        <td>BERNIE 2016</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>25</td>\n",
    "        <td>BERNIE 2016</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>25</td>\n",
    "        <td>BERNIE 2016</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>25</td>\n",
    "        <td>HILLARY FOR AMERICA</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>35</td>\n",
    "        <td>HILLARY FOR AMERICA</td>\n",
    "    </tr>\n",
    "</tbody></table>\n",
    "\n",
    "Hint: We've given you a WITH clause computing a row number for each trial group. Take a look at that table before trying out this problem. This problem requires you to join three tables together (one table gets joined twice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "query_q8 = '''\n",
    "CREATE VIEW joined as\n",
    "WITH num AS (\n",
    "    SELECT MOD(row_number() over () - 1, $n_rows) + 1 AS row_in_group, *\n",
    "    FROM design\n",
    ")\n",
    "SELECT ...\n",
    "FROM ...\n",
    "WHERE ...\n",
    "    AND ...\n",
    "'''\n",
    "\n",
    "# Do not change anything below this line\n",
    "\n",
    "query_q8 = string.Template(query_q8).substitute(locals())\n",
    "%sql drop view if exists joined cascade\n",
    "%sql SET SEED TO $seed\n",
    "%sql $query_q8\n",
    "%sql select * from joined limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "scrolled": true,
    "tags": [
     "solution",
     "q08"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q8 = '''\n",
    "CREATE VIEW joined as\n",
    "WITH num AS (\n",
    "    SELECT MOD(row_number() over () - 1, $n_rows) + 1 AS row_in_group, *\n",
    "    FROM design\n",
    ")\n",
    "SELECT d.trial_id, s1.transaction_amt, s2.cmte_nm\n",
    "FROM num AS d, sample AS s1, sample AS s2\n",
    "WHERE d.row_id = s1.row_id\n",
    "    AND d.row_in_group = s2.row_id\n",
    "'''\n",
    "\n",
    "# Do not change anything below this line\n",
    "\n",
    "query_q8 = string.Template(query_q8).substitute(locals())\n",
    "%sql drop view if exists joined cascade\n",
    "%sql SET SEED TO $seed\n",
    "%sql $query_q8\n",
    "%sql select * from joined limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q08"
    ]
   },
   "outputs": [],
   "source": [
    "r=connection.execute(q_sample)\n",
    "r=connection.execute(\"drop view if exists joined cascade\")\n",
    "r=connection.execute(\"SET SEED TO \" + str(seed))\n",
    "r=connection.execute(query_q8)\n",
    "# If you fail this test, you're shuffling the committee names along with the transaction amounts\n",
    "q1 = \"select sum(transaction_amt) from joined where trial_id = 1 group by cmte_nm order by cmte_nm\"\n",
    "res1 = connection.execute(q1).fetchall()\n",
    "assert res1 != [(19920,), (38002,)]\n",
    "q2 = \"select sum(transaction_amt) from joined where trial_id = 2 group by cmte_nm order by cmte_nm\"\n",
    "assert res1 != connection.execute(q2).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Construct a query `query_q9` that uses the `joined` view to compute the number of small donors for each trial. Recall that a small donor is anyone who contributed \\$200 or less.\n",
    "\n",
    "It should have four columns:\n",
    "\n",
    "- `trial_id`: The number of the trial, from 1 to 1000\n",
    "- `cmte_nm`: The committee name\n",
    "- `small`: The number of small donors for that committee, for that trial\n",
    "- `total`: The number of total donors for that committee, for that trial\n",
    "\n",
    "Order the result by increasing `trial_id` and then by `cmte_nm` within each trial.\n",
    "\n",
    "Your result should look something like:\n",
    "\n",
    "<table>\n",
    "    <tbody><tr>\n",
    "        <th>trial_id</th>\n",
    "        <th>cmte_nm</th>\n",
    "        <th>small</th>\n",
    "        <th>total</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>BERNIE 2016</td>\n",
    "        <td>207</td>\n",
    "        <td>239</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>HILLARY FOR AMERICA</td>\n",
    "        <td>230</td>\n",
    "        <td>252</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>BERNIE 2016</td>\n",
    "        <td>215</td>\n",
    "        <td>239</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>HILLARY FOR AMERICA</td>\n",
    "        <td>222</td>\n",
    "        <td>252</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>BERNIE 2016</td>\n",
    "        <td>216</td>\n",
    "        <td>239</td>\n",
    "    </tr>\n",
    "</tbody></table>\n",
    "\n",
    "Hint: This is similar to how we computed our observed test statistic above. We suggest first computing a column of 1s and 0s that indicate whether a contribution is small. Then, see if you can group that table properly.\n",
    "\n",
    "Then, create a pandas DataFrame called `trials` that contains the `trial_id` for each trial as the index and the generated test statistics as its only column `stats`. It should look like:\n",
    "\n",
    "<table class=\"dataframe\" border=\"1\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>stats</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>trial_id</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>-0.018629</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>0.030285</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>-0.002325</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>-0.010477</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>0.022133</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "solution",
     "q09"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "query_q9 = '''\n",
    "WITH marked AS (\n",
    "    SELECT *, CASE WHEN transaction_amt <= 200 THEN 1 ELSE 0 END AS small\n",
    "    FROM joined\n",
    ")\n",
    "SELECT trial_id, cmte_nm, SUM(small) AS small, COUNT(*) AS total\n",
    "FROM marked\n",
    "GROUP BY trial_id, cmte_nm\n",
    "ORDER BY trial_id, cmte_nm\n",
    "'''\n",
    "\n",
    "# Do not change anything below this line\n",
    "\n",
    "query_q9 = string.Template(query_q9).substitute(locals())\n",
    "%sql SET SEED TO $seed\n",
    "q9_df = pd.DataFrame(connection.execute(query_q9).fetchall(),\n",
    "                     columns=['trial_id', 'cmte_nm', 'small', 'total'])\n",
    "\n",
    "trials = (q9_df\n",
    " .assign(stats=q9_df['small'] / q9_df['total'])\n",
    " .loc[:, ['trial_id', 'stats']]\n",
    " .groupby('trial_id')\n",
    " .agg(lambda g: np.diff(g))\n",
    ")\n",
    "trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q09"
    ]
   },
   "outputs": [],
   "source": [
    "r=connection.execute(\"SET SEED TO \" + str(seed))\n",
    "res = connection.execute(query_q9).fetchall()\n",
    "# If you fail this test, you aren't computing the right number of rows in your query\n",
    "assert len(res) == 2000\n",
    "\n",
    "assert trials.shape == (1000, 1)\n",
    "# Check that there is some variation in the trials\n",
    "assert np.std(trials['stats']) != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the sample distribution\n",
    "\n",
    "Run the following cell to make a plot of the distribution of the proportion differences between Hillary and Bernie. We draw the observed test statistic and the negative of the observed test statistic as red lines on the plot.\n",
    "\n",
    "You should understand why we draw two red lines given our alternative hypothesis and our choice of test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(trials['stats'])\n",
    "plt.axvline(x=observed_stat, color='r')\n",
    "plt.axvline(x= -observed_stat, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Write a query `query_q10` to compute the $p$-value based on the test statistics we generated through the shuffled samples.  We want to find the proportion of the 1000 test statistics that are at least as large in absolute value as the observed statistic.\n",
    "\n",
    "Save your $p$-value in the variable `p_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "solution",
     "q10"
    ]
   },
   "outputs": [],
   "source": [
    "p_value = np.count_nonzero(np.abs(trials['stats']) >= np.abs(observed_stat)) / len(trials)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test",
     "q10"
    ]
   },
   "outputs": [],
   "source": [
    "assert 0 < p_value < 1\n",
    "assert 0.5 < p_value < 1\n",
    "assert 0.85 < p_value < 0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Based on your p-value, can you reject the null hypothesis using a cutoff of 5%? What do you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "for_assignment_type": "solution",
    "tags": [
     "written",
     "solution",
     "q11a"
    ]
   },
   "source": [
    "**SOLUTION:** Our p-value is 0.885 > 0.05, so we fail to reject the null. The data support the null hypothesis that the proportion of small donors to Hillary's and Bernie's campaigns are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might the fact that the California primary is one of the last primaries (it's in June) impact the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "written",
     "solution",
     "q11b"
    ]
   },
   "source": [
    "**SOLUTION:**  In June, it was looking like Clinton was going to win the Democratic nomination and many Sanders supporters began to back Clinton against Trump."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You finished the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting your assignment\n",
    "First, run the next cell to run all the tests at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to submit your assignment to OkPy. The autograder should email you shortly with your autograded score. The autograder will only run once every 30 minutes.\n",
    "\n",
    "**If you're failing tests on the autograder but pass them locally**, you should simulate the autograder by doing the following:\n",
    "\n",
    "1. In the top menu, click Kernel -> Restart and Run all.\n",
    "2. Run the cell above to run each OkPy test.\n",
    "\n",
    "**You must make sure that you pass all the tests when running steps 1 and 2 in order.** If you are still failing autograder tests, you should double check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll submit to okpy\n",
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run this cell to create a PDF to upload to Gradescope.\n",
    "\n",
    "You may get an error about `wkhtmltopdf` the first time you run this cell. If so, install `wkhtmltopdf` and try again.\n",
    "\n",
    "Do not modify the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "no-ok",
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from gs100 import convert\n",
    "convert('hw5_master.ipynb', num_questions=3, solution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure to upload your written answers to Gradescope now!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "timetravel": {
   "allowedContentTypes": [
    "text/plain"
   ],
   "enabled": false,
   "version": "1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}